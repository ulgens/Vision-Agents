"""Utility to generate static SFU event dataclass definitions.

This script inspects ``events_pb2`` at runtime and materialises a static Python
module containing dataclass wrappers for every protobuf message emitted by the
SFU. Run this script whenever the upstream protobuf schema changes.
"""

from __future__ import annotations

import pathlib
from typing import (
    Dict as TypingDict,
)
from collections.abc import Iterable, Sequence

from google.protobuf.descriptor import FieldDescriptor
from google.protobuf.message import Message

from getstream.video.rtc.pb.stream.video.sfu.event import events_pb2
from getstream.video.rtc.pb.stream.video.sfu.models import models_pb2


HEADER_LINES: Sequence[str] = (
    "from __future__ import annotations",
    "",
    "import uuid",
    "from dataclasses import dataclass, field",
    "from datetime import datetime, timezone",
    "from typing import Any, Dict, List, Optional",
    "",
    "from dataclasses_json import DataClassJsonMixin",
    "from google.protobuf.json_format import MessageToDict",
    "from getstream.video.rtc.pb.stream.video.sfu.event import events_pb2",
    "from vision_agents.core.events.base import BaseEvent",
    "",
    "# Note: For enum fields typed as 'int', use the corresponding enum from:",
    "# getstream.video.rtc.pb.stream.video.sfu.models.models_pb2",
    "# Available enums: TrackType, ConnectionQuality, ErrorCode, PeerType, etc.",
    "",
    "",
    "def _to_dict(message) -> Dict[str, Any]:",
    "    try:",
    "        return MessageToDict(message, preserving_proto_field_name=True)",
    "    except Exception:",
    "        return {}",
    "",
)


def _iter_protobuf_messages() -> Iterable[tuple[str, type[Message]]]:
    for name in sorted(dir(events_pb2)):
        attr = getattr(events_pb2, name)
        if isinstance(attr, type) and issubclass(attr, Message):
            yield name, attr


def _class_name(proto_name: str) -> str:
    return proto_name if proto_name.endswith("Event") else proto_name + "Event"


def _collect_message_types() -> TypingDict[str, type[Message]]:
    """Collect all message types referenced in event fields (recursively)."""
    message_types: TypingDict[str, type[Message]] = {}
    to_process: set[str] = set()

    # Collect all message types from events
    for proto_name, message_cls in _iter_protobuf_messages():
        for field_desc in message_cls.DESCRIPTOR.fields:
            if field_desc.type == FieldDescriptor.TYPE_MESSAGE:
                message_type_name = field_desc.message_type.full_name
                if message_type_name.startswith("stream.video.sfu.model"):
                    class_name = message_type_name.split(".")[-1]
                    to_process.add(class_name)

    # Process messages and their nested message types recursively
    processed: set[str] = set()
    while to_process:
        class_name = to_process.pop()
        if class_name in processed:
            continue
        processed.add(class_name)

        if hasattr(models_pb2, class_name):
            message_cls = getattr(models_pb2, class_name)
            message_types[class_name] = message_cls

            # Check for nested message types
            for field_desc in message_cls.DESCRIPTOR.fields:
                if field_desc.type == FieldDescriptor.TYPE_MESSAGE:
                    nested_type_name = field_desc.message_type.full_name
                    if nested_type_name.startswith("stream.video.sfu.model"):
                        nested_class_name = nested_type_name.split(".")[-1]
                        if nested_class_name not in processed:
                            to_process.add(nested_class_name)

    return message_types


def _get_message_type_name(field_descriptor: FieldDescriptor) -> str | None:
    """Get the wrapper class name for a message type field."""
    if field_descriptor.type == FieldDescriptor.TYPE_MESSAGE:
        message_type_name = field_descriptor.message_type.full_name

        # Map known message types to their wrapper classes
        if message_type_name.startswith("stream.video.sfu.model"):
            class_name = message_type_name.split(".")[-1]
            # Return the class name which will be defined at the top
            return class_name

    return None


def _get_enum_type_name(field_descriptor: FieldDescriptor) -> str | None:
    """Get the enum class name for an enum type field for documentation purposes."""
    if field_descriptor.type == FieldDescriptor.TYPE_ENUM:
        enum_type_name = field_descriptor.enum_type.full_name
        # Extract just the class name from the full name (e.g., stream.video.sfu.models.TrackType -> TrackType)
        if enum_type_name.startswith("stream.video.sfu.models."):
            return enum_type_name.split(".")[-1]
    return None


def _get_python_type_from_protobuf_field(field_descriptor: FieldDescriptor) -> str:
    """Determine Python type from protobuf field descriptor.

    Maps protobuf field types to their corresponding Python types.
    All fields are returned as Optional since we want optional semantics.
    """
    # Map protobuf types to Python types
    type_map = {
        FieldDescriptor.TYPE_DOUBLE: "float",
        FieldDescriptor.TYPE_FLOAT: "float",
        FieldDescriptor.TYPE_INT64: "int",
        FieldDescriptor.TYPE_UINT64: "int",
        FieldDescriptor.TYPE_INT32: "int",
        FieldDescriptor.TYPE_FIXED64: "int",
        FieldDescriptor.TYPE_FIXED32: "int",
        FieldDescriptor.TYPE_BOOL: "bool",
        FieldDescriptor.TYPE_STRING: "str",
        FieldDescriptor.TYPE_BYTES: "bytes",
        FieldDescriptor.TYPE_UINT32: "int",
        FieldDescriptor.TYPE_SFIXED32: "int",
        FieldDescriptor.TYPE_SFIXED64: "int",
        FieldDescriptor.TYPE_SINT32: "int",
        FieldDescriptor.TYPE_SINT64: "int",
    }

    # Handle repeated fields (lists)
    if field_descriptor.is_repeated:
        # For enum types in repeated fields - use int, documented in docstring
        if field_descriptor.type == FieldDescriptor.TYPE_ENUM:
            return "Optional[List[int]]"
        # For message types in repeated fields
        elif field_descriptor.type == FieldDescriptor.TYPE_MESSAGE:
            message_type = _get_message_type_name(field_descriptor)
            base_type = message_type if message_type else "Any"
            return f"Optional[List[{base_type}]]"
        # For scalar types in repeated fields
        else:
            base_type = type_map.get(field_descriptor.type, "Any")
            return f"Optional[List[{base_type}]]"

    # Handle message types (nested protobuf messages)
    if field_descriptor.type == FieldDescriptor.TYPE_MESSAGE:
        message_type = _get_message_type_name(field_descriptor)
        return f"Optional[{message_type}]" if message_type else "Optional[Any]"

    # Handle enum types - use int, documented in docstring
    if field_descriptor.type == FieldDescriptor.TYPE_ENUM:
        return "Optional[int]"

    # Handle scalar types - all made optional
    base_type = type_map.get(field_descriptor.type, "Any")
    return f"Optional[{base_type}]"


def _render_message_wrapper(class_name: str, message_cls: type[Message]) -> list[str]:
    """Generate a dataclass wrapper for a protobuf message type (like Participant)."""
    lines = ["@dataclass", f"class {class_name}(DataClassJsonMixin):"]

    # Build docstring with enum field documentation
    docstring_lines = [f"Wrapper for {message_cls.DESCRIPTOR.full_name}."]
    field_descriptors = message_cls.DESCRIPTOR.fields
    enum_fields = []
    for field_desc in field_descriptors:
        if field_desc.type == FieldDescriptor.TYPE_ENUM:
            enum_type_name = _get_enum_type_name(field_desc)
            if enum_type_name:
                enum_fields.append((field_desc.name, enum_type_name))

    if enum_fields:
        docstring_lines.append("")
        docstring_lines.append("Enum fields (use values from models_pb2):")
        for field_name, enum_name in enum_fields:
            docstring_lines.append(f"    - {field_name}: {enum_name}")

    # Add docstring
    if len(docstring_lines) == 1:
        lines.append(f'    """{docstring_lines[0]}"""')
    else:
        lines.append('    """' + docstring_lines[0])
        for line in docstring_lines[1:]:
            lines.append("    " + line)
        lines.append('    """')

    if not field_descriptors:
        lines.append("    pass")
        lines.append("")
        return lines

    # Generate fields with proper types
    for field_desc in field_descriptors:
        field_name = field_desc.name
        python_type = _get_python_type_from_protobuf_field(field_desc)

        # Use proper default for optional fields
        lines.append(f"    {field_name}: {python_type} = None")

    lines.append("")
    lines.append("    @classmethod")
    lines.append(f"    def from_proto(cls, proto_obj) -> '{class_name}':")
    lines.append(f'        """Create from protobuf {class_name}."""')
    lines.append("        if proto_obj is None:")
    lines.append("            return cls()")
    lines.append("        return cls(")

    # Generate field assignments
    for i, field_desc in enumerate(field_descriptors):
        field_name = field_desc.name
        comma = "," if i < len(field_descriptors) - 1 else ""

        # Handle different field types
        if field_desc.type == FieldDescriptor.TYPE_MESSAGE and field_desc.is_repeated:
            # Repeated message fields
            message_type = _get_message_type_name(field_desc)
            if message_type:
                lines.append(
                    f"            {field_name}=[{message_type}.from_proto(item) for item in proto_obj.{field_name}]{comma}"
                )
            else:
                lines.append(
                    f"            {field_name}=list(proto_obj.{field_name}){comma}"
                )
        elif field_desc.type == FieldDescriptor.TYPE_MESSAGE:
            # Single message field
            message_type = _get_message_type_name(field_desc)
            if message_type:
                lines.append(
                    f"            {field_name}={message_type}.from_proto(proto_obj.{field_name}) if proto_obj.HasField('{field_name}') else None{comma}"
                )
            else:
                lines.append(
                    f"            {field_name}=proto_obj.{field_name} if proto_obj.HasField('{field_name}') else None{comma}"
                )
        elif field_desc.is_repeated:
            # Repeated scalar/enum fields - convert to list of ints for enums
            lines.append(
                f"            {field_name}=list(proto_obj.{field_name}){comma}"
            )
        else:
            # Regular scalar/enum fields
            lines.append(f"            {field_name}=proto_obj.{field_name}{comma}")

    lines.append("        )")
    lines.append("")
    return lines


def _render_class(proto_name: str, message_cls: type[Message]) -> list[str]:
    class_name = _class_name(proto_name)
    event_type = message_cls.DESCRIPTOR.full_name

    # Get field descriptors for this message
    field_descriptors = message_cls.DESCRIPTOR.fields

    lines = ["@dataclass", f"class {class_name}(BaseEvent):"]
    lines.append(
        f'    """Dataclass event for {message_cls.__module__}.{message_cls.__name__}."""'
    )

    # Override type field with the specific event type
    lines.append(f'    type: str = field(default="{event_type}", init=False)')

    # Add payload field (optional to match BaseEvent pattern)
    lines.append(
        f"    payload: Optional[events_pb2.{proto_name}] = field(default=None, repr=False)"
    )

    # Add property fields for each protobuf field (skip fields that conflict with BaseEvent)
    base_event_fields = {"type", "event_id", "timestamp", "session_id", "user_metadata"}
    for field_desc in field_descriptors:
        field_name = field_desc.name
        if (
            field_name in base_event_fields
        ):  # Skip fields that conflict with BaseEvent fields
            continue
        type_hint = _get_python_type_from_protobuf_field(field_desc)
        lines.append("")
        lines.append("    @property")
        lines.append(f"    def {field_name}(self) -> {type_hint}:")

        # Build docstring with enum information if applicable
        docstring = f"Access {field_name} field from the protobuf payload."
        if field_desc.type == FieldDescriptor.TYPE_ENUM:
            enum_type_name = _get_enum_type_name(field_desc)
            if enum_type_name:
                docstring += f" Use models_pb2.{enum_type_name} enum."

        lines.append(f'        """{docstring}"""')
        lines.append("        if self.payload is None:")
        lines.append("            return None")

        # Handle message type fields - wrap them in our dataclass
        if field_desc.type == FieldDescriptor.TYPE_MESSAGE:
            message_type = _get_message_type_name(field_desc)
            if message_type:
                if field_desc.is_repeated:
                    lines.append(
                        f"        proto_list = getattr(self.payload, '{field_name}', [])"
                    )
                    lines.append(
                        f"        return [{message_type}.from_proto(item) for item in proto_list] if proto_list else None"
                    )
                else:
                    lines.append(
                        f"        proto_val = getattr(self.payload, '{field_name}', None)"
                    )
                    lines.append(
                        f"        return {message_type}.from_proto(proto_val) if proto_val is not None else None"
                    )
            else:
                lines.append(
                    f"        return getattr(self.payload, '{field_name}', None)"
                )
        else:
            # Scalar or enum fields
            lines.append(f"        return getattr(self.payload, '{field_name}', None)")

    lines.append("")
    lines.append("    @classmethod")
    lines.append(
        f"    def from_proto(cls, proto_obj: events_pb2.{proto_name}, **extra):"
    )
    lines.append('        """Create event instance from protobuf message."""')
    lines.append("        return cls(payload=proto_obj, **extra)")
    lines.append("")
    lines.append("    def as_dict(self) -> Dict[str, Any]:")
    lines.append('        """Convert protobuf payload to dictionary."""')
    lines.append("        if self.payload is None:")
    lines.append("            return {}")
    lines.append("        return _to_dict(self.payload)")
    lines.append("")
    lines.append("    def __getattr__(self, item: str):")
    lines.append('        """Delegate attribute access to protobuf payload."""')
    lines.append("        if self.payload is not None:")
    lines.append("            return getattr(self.payload, item)")
    lines.append(
        "        raise AttributeError(f\"'{self.__class__.__name__}' object has no attribute '{item}'\")"
    )
    lines.append("")
    return lines


def _render_module_body() -> tuple[list[str], list[str], list[str]]:
    """Generate message wrappers and event classes.

    Returns:
        Tuple of (message_wrapper_blocks, event_class_blocks, event_class_names)
    """
    # Collect all message types used in events
    message_types = _collect_message_types()

    # Generate message wrapper classes
    message_wrapper_blocks: list[str] = []
    for class_name in sorted(message_types.keys()):
        message_cls = message_types[class_name]
        wrapper_lines = _render_message_wrapper(class_name, message_cls)
        message_wrapper_blocks.append("\n".join(wrapper_lines))

    # Generate event classes
    event_class_blocks: list[str] = []
    event_class_names: list[str] = []

    for proto_name, message_cls in _iter_protobuf_messages():
        class_name = _class_name(proto_name)
        event_class_names.append(class_name)
        class_lines = _render_class(proto_name, message_cls)
        event_class_blocks.append("\n".join(class_lines))

    return message_wrapper_blocks, event_class_blocks, event_class_names


def _build_module() -> str:
    message_wrappers, event_classes, event_names = _render_module_body()

    parts: list[str] = [
        '"""Auto-generated SFU event dataclasses. Do not edit manually."""',
        "# Generated by _generate_sfu_events.py",
        *HEADER_LINES,
    ]

    # Add section header for message wrappers
    if message_wrappers:
        parts.extend(
            [
                "# " + "=" * 78,
                "# Message Type Wrappers",
                "# These are wrappers for protobuf message types used in events",
                "# " + "=" * 78,
                "",
            ]
        )
        parts.extend(message_wrappers)
        parts.append("")

    # Add section header for event classes
    parts.extend(
        [
            "# " + "=" * 78,
            "# Event Classes",
            "# " + "=" * 78,
            "",
        ]
    )
    parts.extend(event_classes)

    # Add exports
    exports_section = [
        "",
        "__all__ = (",
        *[f'    "{name}",' for name in event_names],
        ")",
    ]

    parts.extend(exports_section)

    return "\n".join(parts) + "\n"


def verify_generated_classes() -> bool:
    """Verify that generated classes match protobuf definitions.

    Returns:
        True if all checks pass, False otherwise.
    """
    import importlib.util
    import sys

    # Import the generated module
    target_path = pathlib.Path(__file__).parent / "core" / "edge" / "sfu_events.py"
    if not target_path.exists():
        print("Error: sfu_events.py not found. Run generation first.")
        return False

    # Dynamically load the module
    spec = importlib.util.spec_from_file_location("sfu_events", target_path)
    if spec is None or spec.loader is None:
        print("Error: Could not load sfu_events module")
        return False

    sfu_events = importlib.util.module_from_spec(spec)
    sys.modules["sfu_events"] = sfu_events
    spec.loader.exec_module(sfu_events)

    all_valid = True

    for proto_name, message_cls in _iter_protobuf_messages():
        class_name = _class_name(proto_name)

        # Check if class exists in generated module
        if not hasattr(sfu_events, class_name):
            print(f"✗ Class {class_name} not found in generated module")
            all_valid = False
            continue

        event_class = getattr(sfu_events, class_name)

        # Verify it's a BaseEvent subclass
        if not hasattr(event_class, "__mro__"):
            print(f"✗ {class_name} is not a class")
            all_valid = False
            continue

        # Check field correspondence
        proto_fields = {f.name: f for f in message_cls.DESCRIPTOR.fields}

        # Check that all protobuf fields are accessible via properties
        for field_name, field_desc in proto_fields.items():
            if field_name in {
                "type",
                "event_id",
                "timestamp",
                "session_id",
                "user_metadata",
            }:
                continue  # Skip BaseEvent fields

            if not hasattr(event_class, field_name):
                print(
                    f"✗ {class_name} missing property for protobuf field: {field_name}"
                )
                all_valid = False
                continue

            # Verify it's a property (check on the class itself, not an instance)
            attr = getattr(event_class, field_name, None)
            if not isinstance(attr, property):
                print(
                    f"✗ {class_name}.{field_name} is not a property (type: {type(attr).__name__})"
                )
                all_valid = False
                continue

        print(f"✓ {class_name} verified ({len(proto_fields)} protobuf fields)")

    return all_valid


def verify_field_types() -> None:
    """Verify and display field type mappings for all protobuf messages."""
    print("\n" + "=" * 80)
    print("Field Type Verification Report")
    print("=" * 80 + "\n")

    for proto_name, message_cls in _iter_protobuf_messages():
        class_name = _class_name(proto_name)
        print(f"\n{class_name} ({proto_name}):")
        print(f"  Protobuf type: {message_cls.DESCRIPTOR.full_name}")

        field_descriptors = message_cls.DESCRIPTOR.fields
        if not field_descriptors:
            print("  (no fields)")
            continue

        for field_desc in field_descriptors:
            field_name = field_desc.name
            if field_name in {
                "type",
                "event_id",
                "timestamp",
                "session_id",
                "user_metadata",
            }:
                continue

            python_type = _get_python_type_from_protobuf_field(field_desc)
            proto_type_name = field_desc.type
            label = (
                "repeated"
                if field_desc.is_repeated
                else "optional"
                if hasattr(field_desc, "is_optional")
                else "required"
            )

            print(f"  - {field_name}: type={proto_type_name} ({label}) → {python_type}")


def main() -> None:
    import sys

    # Generate sfu_events.py in the core/edge directory
    target_path = pathlib.Path(__file__).parent / "core" / "edge" / "sfu_events.py"
    target_path.write_text(_build_module(), encoding="utf-8")
    print(f"Regenerated {target_path}")

    # Verify field types
    if "--verify-types" in sys.argv:
        verify_field_types()

    # Verify generated classes
    if "--verify" in sys.argv:
        print("\nVerifying generated classes...")
        if verify_generated_classes():
            print("\n✓ All verifications passed!")
        else:
            print("\n✗ Some verifications failed!")
            sys.exit(1)


if __name__ == "__main__":
    main()
